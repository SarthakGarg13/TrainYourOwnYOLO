{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Object Detection\n",
    "\n",
    "### Image lassification vs Object Detection\n",
    "\n",
    "In <b>classification</b>, there’s generally an image with a single object as the focus and the task is to say what that image is\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/1*8GVucX9yhnL21KCtcyFDRQ.png)\n",
    "\n",
    "But when we look at the world around us, we carry out far more complex task\n",
    "\n",
    "![Alt Text](https://cdn-images-1.medium.com/max/1600/1*NdwfHMrW3rpj5SW_VQtWVw.png)\n",
    "\n",
    "We see complicated sights with multiple overlapping objects, and different backgrounds and we not only classify these different objects but also identify their boundaries, differences, and relations to one another!\n",
    "\n",
    "Can CNNs help us with such complex tasks? Yes.\n",
    "\n",
    "![Alt Text](https://irenelizihui.files.wordpress.com/2016/02/cnn2.png)\n",
    "\n",
    "![Alt Text](https://www.pyimagesearch.com/wp-content/uploads/2017/03/imagenet_vgg16.png)\n",
    "\n",
    "- We can take a classifier like VGGNet or Inception and turn it into an object detector by sliding a small window across the image\n",
    "- At each step you run the classifier to get a prediction of what sort of object is inside the current window. \n",
    "- Using a sliding window gives several hundred or thousand predictions for that image, but you only keep the ones the classifier is the most certain about.\n",
    "- This approach works but it’s obviously going to be very slow, since you need to run the classifier many times.\n",
    "\n",
    "\n",
    "### What is YOLO?\n",
    "\n",
    "- YOLO takes a completely different approach. \n",
    "- It’s not a traditional classifier that is repurposed to be an object detector. \n",
    "- YOLO actually looks at the image just once (hence its name: You Only Look Once) but in a clever way.\n",
    "\n",
    "### How does the YOLO Framework Function?\n",
    "\n",
    "- YOLO first takes an input image:\n",
    "\n",
    "![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-17-43-42.png)\n",
    "\n",
    "- The framework then divides the input image into grids (say a 3 X 3 grid):\n",
    "\n",
    "![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-17-46-32.png)\n",
    "\n",
    "- Image classification and localization are applied on each grid. YOLO then predicts the bounding boxes and their corresponding class probabilities for objects.\n",
    "\n",
    "#### Let's break it down\n",
    "\n",
    "<b>Training Data</b>\n",
    "- We need to pass the labelled data to the model in order to train it.\n",
    "    - Suppose we divide image into a grid of size 3 X 3\n",
    "    - There are a total of 3 classes(Pedestrian, Car, and Motorcycle) which we want the objects to be classified into.\n",
    "    - label y will be an eight dimensional vector:\n",
    "    \n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-01-24.png)\n",
    "        \n",
    "        - pc defines whether an object is present in the grid or not (it is the probability)\n",
    "        - bx, by, bh, bw specify the bounding box if there is an object\n",
    "        - c1, c2, c3 represent the classes. So, if the object is a car, c2 will be 1 and c1 & c3 will be 0, and so on\n",
    "     \n",
    "- Let’s say we select the first grid from the above example:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-08-47.png)\n",
    "\n",
    "    - Since there is no object in this grid, pc will be zero and the y label for this grid will be:\n",
    "\n",
    "     ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-11-15.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let’s take another grid in which we have a car (c2 = 1):\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-15-50.png)\n",
    "    \n",
    "    - Even if an object spans out to more than one grid, it will only be assigned to a single grid in which its mid-point is located.\n",
    "    \n",
    "    - y label for this grid will be:\n",
    "    \n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-27-25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Now we have an input image and it’s corresponding target vector. Using the above example (input image – 100 X 100 X 3, output – 3 X 3 X 8), our model will be trained as follows:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-46-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Encode Bounding Boxes?\n",
    "\n",
    "As we saw earlier, bx, by, bh, and bw are calculated relative to the grid cell we are dealing with. Let’s understand this concept with an example. Consider the center-right grid which contains a car:\n",
    "\n",
    " ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-19-23-07.png)\n",
    "\n",
    "So, bx, by, bh, and bw will be calculated relative to this grid only. The y label for this grid will be:\n",
    "\n",
    " ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-27-25.png)\n",
    "\n",
    "pc = 1 since there is an object in this grid and since it is a car, c2 = 1. Now, let’s see how to decide bx, by, bh, and bw. In YOLO, the coordinates assigned to all the grids are:\n",
    "\n",
    " ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-19-35-31.png)\n",
    "\n",
    "bx, by are the x and y coordinates of the midpoint of the object with respect to this grid. In this case, it will be (around) bx = 0.4 and by = 0.3:\n",
    "\n",
    " ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-19-39-51.png)\n",
    "\n",
    "bh is the ratio of the height of the bounding box (red box in the above example) to the height of the corresponding grid cell, which in our case is around 0.9. So,  bh = 0.9. bw is the ratio of the width of the bounding box to the width of the grid cell. So, bw = 0.5 (approximately). The y label for this grid will be:\n",
    "\n",
    "   ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-16-12-44-34.png)\n",
    "\n",
    "Notice here that bx and by will always range between 0 and 1 as the midpoint will always lie within the grid. Whereas bh and bw can be more than 1 in case the dimensions of the bounding box are more than the dimension of the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection over Union and Non-Max Suppression:\n",
    "    \n",
    "- Consider the actual and predicted bounding boxes for a car as shown below:\n",
    "    \n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-16-13-07-50.png)\n",
    "    \n",
    "    - Here, the red box is the actual bounding box and the blue box is the predicted one. How can we decide whether it is a good prediction or not? IoU, or Intersection over Union, will calculate the area of the intersection over union of these two boxes. That area will be:\n",
    "    \n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-16-13-12-02.png)\n",
    "    \n",
    "        - IoU = Area of the intersection / Area of the union, i.e.\n",
    "\n",
    "IoU = Area of yellow box / Area of green box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Max Suppression:\n",
    "\n",
    "- There is one more technique that can improve the output of YOLO significantly\n",
    "\n",
    "- One of the most common problems with object detection algorithms is that rather than detecting an object just once, they might detect it multiple times. Consider the below image:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-16-13-32-40.png)\n",
    "\n",
    "- Here, the cars are identified more than once. The Non-Max Suppression technique cleans up this up so that we get only a single detection per object. Let’s see how this approach works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It first looks at the probabilities associated with each detection and takes the largest one. In the above image, 0.9 is the highest probability, so the box with 0.9 probability will be selected first:\n",
    "\n",
    "    ![Alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-12-08-14.png)\n",
    "\n",
    "2. Now, it looks at all the other boxes in the image. The boxes which have high IoU with the current box are suppressed. So, the boxes with 0.6 and 0.7 probabilities will be suppressed in our example:\n",
    "\n",
    "    ![Alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-12-09-17.png)\n",
    "\n",
    "3. After the boxes have been suppressed, it selects the next box from all the boxes with the highest probability, which is 0.8 in our case:\n",
    "\n",
    "    ![Alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-12-10-38.png)\n",
    "\n",
    "4. Again it will look at the IoU of this box with the remaining boxes and compress the boxes with a high IoU:\n",
    "\n",
    "    ![Alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-12-11-35.png)\n",
    "\n",
    "5. We repeat these steps until all the boxes have either been selected or compressed and we get the final bounding boxes:\n",
    "\n",
    "    ![Alt text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-12-21-31.png)\n",
    "\n",
    "This is what Non-Max Suppression is all about. We are taking the boxes with maximum probability and suppressing the close-by boxes with non-max probabilities. \n",
    "\n",
    "#### Let's Summarize\n",
    "\n",
    "- Discard all the boxes having probabilities less than or equal to a pre-defined threshold (say, 0.5)\n",
    "- For the remaining boxes:\n",
    "    - Pick the box with the highest probability and take that as the output prediction\n",
    "    - Discard any other box which has IoU greater than the threshold with the output box from the above step\n",
    "    - Repeat step 2 until all the boxes are either taken as the output prediction or discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor Boxes\n",
    "\n",
    "What if there are multiple objects in a single grid?\n",
    "\n",
    "- Consider the following image, divided into a 3 X 3 grid:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-13-18-38.png)\n",
    "\n",
    "- The midpoint of both the objects lies in the same grid. This is how the actual bounding boxes for the objects will be:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-13-20-41.png)\n",
    "\n",
    "- Let's take two achor boxes to make the concept easy to understand:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-13-36-28.png)\n",
    "\n",
    "- This is how the y label for YOLO <b>without</b> anchor boxes looks like:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-15-18-01-24.png)\n",
    "\n",
    "- The y label for YOLO <b>with</b> anchor boxes will be:\n",
    "\n",
    "    ![Alt Text](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-13-33-31.png)\n",
    "\n",
    "- The first 8 rows belong to anchor box 1 and the remaining 8 belongs to anchor box 2. The output in this case, instead of 3 X 3 X 8 (using a 3 X 3 grid and 3 classes), will be 3 X 3 X 16 (since we are using 2 anchors).\n",
    "\n",
    "##### So, for each grid, we can detect two or more objects based on the number of anchors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's combine all the above ideas \n",
    "\n",
    "YOLO divides up the image into a grid of 13 by 13 cells:\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Grid@2x.png)\n",
    "\n",
    "- Each of these cells is responsible for predicting 5 bounding boxes. \n",
    "- A bounding box describes the rectangle that encloses an object.\n",
    "- YOLO also outputs a confidence score that tells us how certain it is that the predicted bounding box actually encloses some object.\n",
    "- This score doesn’t say anything about what kind of object is in the box, just if the shape of the box is any good.\n",
    "\n",
    "The predicted bounding boxes may look something like the following (the higher the confidence score, the fatter the box is drawn):\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Boxes@2x.png)\n",
    "\n",
    "- For each bounding box, the cell also predicts a class. \n",
    "- This works just like a classifier: it gives a probability distribution over all the possible classes. \n",
    "- YOLO was trained on the PASCAL VOC dataset, which can detect 20 different classes such as:\n",
    "\n",
    "- bicycle\n",
    "- boat\n",
    "- car\n",
    "- cat\n",
    "- dog\n",
    "- person\n",
    "\n",
    "- The confidence score for the bounding box and the class prediction are combined into one final score that tells us the probability that this bounding box contains a specific type of object. \n",
    "- For example, the big fat yellow box on the left is 85% sure it contains the object “dog”:\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Scores@2x.png)\n",
    "\n",
    "- Since there are 13×13 = 169 grid cells and each cell predicts 5 bounding boxes, we end up with 845 bounding boxes in total. \n",
    "- It turns out that most of these boxes will have very low confidence scores, so we only keep the boxes whose final score is 30% or more (you can change this threshold depending on how accurate you want the detector to be).\n",
    "\n",
    "The final prediction is then:\n",
    "\n",
    "![Alt Text](http://machinethink.net/images/yolo/Prediction@2x.png)\n",
    "\n",
    "- From the 845 total bounding boxes we only kept these three because they gave the best results. \n",
    "- But note that even though there were 845 separate predictions, they were all made at the same time — the neural network just ran once. And that’s why YOLO is so powerful and fast.\n",
    "\n",
    "The architecture of YOLO is simple, it’s just a convolutional neural network:\n",
    "\n",
    "![Alt Text](https://i.imgur.com/QH0CvRN.png)\n",
    "\n",
    "This neural network only uses standard layer types: convolution with a 3×3 kernel and max-pooling with a 2×2 kernel. No fancy stuff. There is no fully-connected layer in YOLOv2.\n",
    "\n",
    "The very last convolutional layer has a 1×1 kernel and exists to reduce the data to the shape 13×13×125. This 13×13 should look familiar: that is the size of the grid that the image gets divided into.\n",
    "\n",
    "So we end up with 125 channels for every grid cell. These 125 numbers contain the data for the bounding boxes and the class predictions. Why 125? Well, each grid cell predicts 5 bounding boxes and a bounding box is described by 25 data elements:\n",
    "\n",
    "- x, y, width, height for the bounding box’s rectangle\n",
    "- the confidence score\n",
    "- the probability distribution over the classes\n",
    "\n",
    "Using YOLO is simple: you give it an input image (resized to 416×416 pixels), it goes through the convolutional network in a single pass, and comes out the other end as a 13×13×125 tensor describing the bounding boxes for the grid cells. All you need to do then is compute the final scores for the bounding boxes and throw away the ones scoring lower than 30%.\n",
    "\n",
    "Paper here\n",
    "https://arxiv.org/pdf/1612.08242v1.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
